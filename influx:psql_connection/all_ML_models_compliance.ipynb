{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model1\n",
    "from datetime import datetime\n",
    "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n",
    "                 print_cm=True, cm_cmap=plt.cm.Greens):\n",
    "    \n",
    "    \n",
    "    # to store results at various phases\n",
    "    results = dict()\n",
    "    \n",
    "    # time at which model starts training \n",
    "    train_start_time = datetime.now()\n",
    "    print('training the model..')\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Done \\n \\n')\n",
    "    train_end_time = datetime.now()\n",
    "    results['training_time'] =  train_end_time - train_start_time\n",
    "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
    "    \n",
    "    \n",
    "    # predict test data\n",
    "    print('Predicting test data')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_end_time = datetime.now()\n",
    "    print('Done \\n \\n')\n",
    "    results['testing_time'] = test_end_time - test_start_time\n",
    "    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n",
    "    results['predicted'] = y_pred\n",
    "   \n",
    "\n",
    "    # calculate overall accuracty of the model\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    # store accuracy in results\n",
    "    results['accuracy'] = accuracy\n",
    "    print('---------------------')\n",
    "    print('|      Accuracy      |')\n",
    "    print('---------------------')\n",
    "    print('\\n    {}\\n\\n'.format(accuracy))\n",
    "    \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results['confusion_matrix'] = cm\n",
    "    if print_cm: \n",
    "        print('--------------------')\n",
    "        print('| Confusion Matrix |')\n",
    "        print('--------------------')\n",
    "        print('\\n {}'.format(cm))\n",
    "        \n",
    "    # plot confusin matrix\n",
    "    #plt.figure(figsize=(8,8))\n",
    "    #plt.grid(b=False)\n",
    "    #plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "    #plt.show()\n",
    "    \n",
    "    # get classification report\n",
    "    print('-------------------------')\n",
    "    print('| Classifiction Report |')\n",
    "    print('-------------------------')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred)\n",
    "    # store report in results\n",
    "    results['classification_report'] = classification_report\n",
    "    print(classification_report)\n",
    "    \n",
    "    # add the trained  model to the results\n",
    "    results['model'] = model\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_attributes(model):\n",
    "    # Estimator that gave highest score among all the estimators formed in GridSearch\n",
    "    print('--------------------------')\n",
    "    print('|      Best Estimator     |')\n",
    "    print('--------------------------')\n",
    "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
    "\n",
    "\n",
    "    # parameters that gave best results while performing grid search\n",
    "    print('--------------------------')\n",
    "    print('|     Best parameters     |')\n",
    "    print('--------------------------')\n",
    "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
    "\n",
    "\n",
    "    #  number of cross validation splits\n",
    "    print('---------------------------------')\n",
    "    print('|   No of CrossValidation sets   |')\n",
    "    print('--------------------------------')\n",
    "    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n",
    "\n",
    "\n",
    "    # Average cross validated score of the best estimator, from the Grid Search \n",
    "    print('--------------------------')\n",
    "    print('|        Best Score       |')\n",
    "    print('--------------------------')\n",
    "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:01.994345\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.000238\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.82\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[19  0  0]\n",
      " [ 0  8  7]\n",
      " [ 0  2 14]]\n",
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.80      0.53      0.64        15\n",
      "           2       0.67      0.88      0.76        16\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.82      0.80      0.80        50\n",
      "weighted avg       0.83      0.82      0.81        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amimalli/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.76886512        nan 0.78966132        nan 0.78966132        nan\n",
      " 0.79976233        nan 0.79976233        nan 0.79976233        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# start Grid search\n",
    "parameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\n",
    "log_reg_grid_results =  perform_model(log_reg_grid, x_train, y_train, x_test, y_test, class_labels=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8,8))\n",
    "#plt.grid(b=False)\n",
    "#plot_confusion_matrix(log_reg_grid_results['confusion_matrix'], classes=labels, cmap=plt.cm.Greens, )\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear SVC with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:00.087121\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.000176\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.78\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[19  0  0]\n",
      " [ 1  6  8]\n",
      " [ 0  2 14]]\n",
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        19\n",
      "           1       0.75      0.40      0.52        15\n",
      "           2       0.64      0.88      0.74        16\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.76      0.74        50\n",
      "weighted avg       0.79      0.78      0.76        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amimalli/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\n",
    "lr_svc = LinearSVC(tol=0.00005)\n",
    "lr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=-1, verbose=1)\n",
    "lr_svc_grid_results = perform_model(lr_svc_grid, x_train, y_train, x_test, y_test, class_labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tLinearSVC(C=1, tol=5e-05)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 1}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 5\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.7699999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_attributes(lr_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kernel SVM with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:00.035258\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.000636\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.78\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[19  0  0]\n",
      " [ 0  8  7]\n",
      " [ 0  4 12]]\n",
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.67      0.53      0.59        15\n",
      "           2       0.63      0.75      0.69        16\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.77      0.76      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[2,8,16],\\\n",
    "              'gamma': [ 0.0078125, 0.125, 2]}\n",
    "rbf_svm = SVC(kernel='rbf')\n",
    "rbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters, n_jobs=-1)\n",
    "rbf_svm_grid_results = perform_model(rbf_svm_grid, x_train, y_train, x_test, y_test, class_labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tSVC(C=2, gamma=0.125)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 2, 'gamma': 0.125}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 5\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.8099999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_attributes(rbf_svm_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Trees with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:00.078046\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.000341\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.76\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[18  1  0]\n",
      " [ 0  9  6]\n",
      " [ 0  5 11]]\n",
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.60      0.60      0.60        15\n",
      "           2       0.65      0.69      0.67        16\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.75      0.74      0.75        50\n",
      "weighted avg       0.77      0.76      0.76        50\n",
      "\n",
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tDecisionTreeClassifier(max_depth=3)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'max_depth': 3}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 5\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.7700000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'max_depth':np.arange(3,10,2)}\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=-1)\n",
    "dt_grid_results = perform_model(dt_grid, x_train, y_train, x_test, y_test, class_labels=y)\n",
    "print_grid_search_attributes(dt_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest Classifier with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:05.348872\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.003486\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.74\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[19  0  0]\n",
      " [ 0  8  7]\n",
      " [ 0  6 10]]\n",
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.57      0.53      0.55        15\n",
      "           2       0.59      0.62      0.61        16\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.72      0.72      0.72        50\n",
      "weighted avg       0.74      0.74      0.74        50\n",
      "\n",
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tRandomForestClassifier(max_depth=5, n_estimators=30)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'max_depth': 5, 'n_estimators': 30}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 5\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'n_estimators': np.arange(10,201,20), 'max_depth':np.arange(3,15,2)}\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_grid = GridSearchCV(rfc, param_grid=params, n_jobs=-1)\n",
    "rfc_grid_results = perform_model(rfc_grid, x_train, y_train, x_test, y_test, class_labels=y)\n",
    "print_grid_search_attributes(rfc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradient Boosted Decision Trees With GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:04.710234\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.001361\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.76\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[19  0  0]\n",
      " [ 0  8  7]\n",
      " [ 0  5 11]]\n",
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.62      0.53      0.57        15\n",
      "           2       0.61      0.69      0.65        16\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.74      0.74      0.74        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n",
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tGradientBoostingClassifier(max_depth=6, n_estimators=150)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'max_depth': 6, 'n_estimators': 150}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 5\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_grid = {'max_depth': np.arange(5,8,1), \\\n",
    "             'n_estimators':np.arange(130,170,10)}\n",
    "gbdt = GradientBoostingClassifier()\n",
    "gbdt_grid = GridSearchCV(gbdt, param_grid=param_grid, n_jobs=-1)\n",
    "gbdt_grid_results = perform_model(gbdt_grid, x_train, y_train, x_test, y_test, class_labels=y)\n",
    "print_grid_search_attributes(gbdt_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     Accuracy     Error\n",
      "                     ----------   --------\n",
      "Logistic Regression : 82.0%       18.0%\n",
      "Linear SVC          : 78.0%       22.0% \n",
      "rbf SVM classifier  : 78.0%      22.0% \n",
      "DecisionTree        : 76.0%      24.0% \n",
      "Random Forest       : 74.0%      26.0% \n",
      "GradientBoosting DT : 74.0%      26.0% \n"
     ]
    }
   ],
   "source": [
    "print('\\n                     Accuracy     Error')\n",
    "print('                     ----------   --------')\n",
    "print('Logistic Regression : {:.04}%       {:.04}%'.format(log_reg_grid_results['accuracy'] * 100,\\\n",
    "                                                  100-(log_reg_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('Linear SVC          : {:.04}%       {:.04}% '.format(lr_svc_grid_results['accuracy'] * 100,\\\n",
    "                                                        100-(lr_svc_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('rbf SVM classifier  : {:.04}%      {:.04}% '.format(rbf_svm_grid_results['accuracy'] * 100,\\\n",
    "                                                          100-(rbf_svm_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('DecisionTree        : {:.04}%      {:.04}% '.format(dt_grid_results['accuracy'] * 100,\\\n",
    "                                                        100-(dt_grid_results['accuracy'] * 100)))\n",
    "\n",
    "print('Random Forest       : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n",
    "                                                           100-(rfc_grid_results['accuracy'] * 100)))\n",
    "print('GradientBoosting DT : {:.04}%      {:.04}% '.format(rfc_grid_results['accuracy'] * 100,\\\n",
    "                                                        100-(rfc_grid_results['accuracy'] * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
