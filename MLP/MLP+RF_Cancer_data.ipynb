{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  label  \n",
       "0          0.4601                  0.11890    0.0  \n",
       "1          0.2750                  0.08902    0.0  \n",
       "2          0.3613                  0.08758    0.0  \n",
       "3          0.6638                  0.17300    0.0  \n",
       "4          0.2364                  0.07678    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_data = breast.data\n",
    "\n",
    "breast_data.shape\n",
    "\n",
    "breast_labels = breast.target\n",
    "\n",
    "breast_labels.shape\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "labels = np.reshape(breast_labels,(569,1))\n",
    "\n",
    "final_breast_data = np.concatenate([breast_data,labels],axis=1)\n",
    "\n",
    "final_breast_data.shape\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "breast_dataset = pd.DataFrame(final_breast_data)\n",
    "\n",
    "features = breast.feature_names\n",
    "\n",
    "features\n",
    "\n",
    "\n",
    "features_labels = np.append(features,'label')\n",
    "\n",
    "\n",
    "\n",
    "breast_dataset.columns = features_labels\n",
    "\n",
    "breast_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    357\n",
       "0.0    212\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=breast_dataset.loc[:, breast_dataset.columns != 'label']\n",
    "y=breast_dataset.label\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=101)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu',kernel_initializer='he_uniform', input_shape=(30,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.add(Dropout(0.1, input_shape=(30,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Dense(16, activation='relu', input_shape=(30,)))\n",
    "#model.add(Dropout(0.1, input_shape=(30,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "#model.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "#classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#output_dim = 10\n",
    "#input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 100 \n",
    "nb_epoch = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7827 - accuracy: 0.3806 - val_loss: 0.7011 - val_accuracy: 0.4043\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7225 - accuracy: 0.3963 - val_loss: 0.6557 - val_accuracy: 0.4362\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.4278 - val_loss: 0.6161 - val_accuracy: 0.4840\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.4934 - val_loss: 0.5819 - val_accuracy: 0.5745\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5826 - accuracy: 0.5459 - val_loss: 0.5521 - val_accuracy: 0.6223\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.6194 - val_loss: 0.5254 - val_accuracy: 0.6702\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.6693 - val_loss: 0.5016 - val_accuracy: 0.7287\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7349 - val_loss: 0.4793 - val_accuracy: 0.8032\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7953 - val_loss: 0.4579 - val_accuracy: 0.8298\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8346 - val_loss: 0.4375 - val_accuracy: 0.8511\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8766 - val_loss: 0.4181 - val_accuracy: 0.8617\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8976 - val_loss: 0.3994 - val_accuracy: 0.8670\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.9108 - val_loss: 0.3817 - val_accuracy: 0.8830\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.9370 - val_loss: 0.3647 - val_accuracy: 0.9096\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.9449 - val_loss: 0.3485 - val_accuracy: 0.9149\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.9528 - val_loss: 0.3330 - val_accuracy: 0.9202\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.9606 - val_loss: 0.3184 - val_accuracy: 0.9202\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.9659 - val_loss: 0.3047 - val_accuracy: 0.9255\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.9685 - val_loss: 0.2921 - val_accuracy: 0.9255\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.9711 - val_loss: 0.2803 - val_accuracy: 0.9255\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.9711 - val_loss: 0.2692 - val_accuracy: 0.9255\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.9711 - val_loss: 0.2588 - val_accuracy: 0.9309\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2026 - accuracy: 0.9711 - val_loss: 0.2491 - val_accuracy: 0.9309\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1909 - accuracy: 0.9711 - val_loss: 0.2403 - val_accuracy: 0.9362\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9711 - val_loss: 0.2321 - val_accuracy: 0.9362\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.9685 - val_loss: 0.2245 - val_accuracy: 0.9362\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1612 - accuracy: 0.9685 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.9711 - val_loss: 0.2115 - val_accuracy: 0.9415\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.9711 - val_loss: 0.2058 - val_accuracy: 0.9362\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9711 - val_loss: 0.2006 - val_accuracy: 0.9362\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9711 - val_loss: 0.1960 - val_accuracy: 0.9362\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.9711 - val_loss: 0.1917 - val_accuracy: 0.9309\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9738 - val_loss: 0.1879 - val_accuracy: 0.9362\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9738 - val_loss: 0.1843 - val_accuracy: 0.9362\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.9764 - val_loss: 0.1810 - val_accuracy: 0.9362\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9764 - val_loss: 0.1781 - val_accuracy: 0.9362\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9764 - val_loss: 0.1753 - val_accuracy: 0.9362\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.9764 - val_loss: 0.1728 - val_accuracy: 0.9362\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0954 - accuracy: 0.9764 - val_loss: 0.1704 - val_accuracy: 0.9362\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9764 - val_loss: 0.1683 - val_accuracy: 0.9362\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9764 - val_loss: 0.1663 - val_accuracy: 0.9362\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9764 - val_loss: 0.1643 - val_accuracy: 0.9362\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9764 - val_loss: 0.1624 - val_accuracy: 0.9362\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9764 - val_loss: 0.1607 - val_accuracy: 0.9362\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9764 - val_loss: 0.1591 - val_accuracy: 0.9362\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9764 - val_loss: 0.1575 - val_accuracy: 0.9362\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9764 - val_loss: 0.1560 - val_accuracy: 0.9362\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9764 - val_loss: 0.1546 - val_accuracy: 0.9362\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9790 - val_loss: 0.1533 - val_accuracy: 0.9362\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.1518 - val_accuracy: 0.9362\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9790 - val_loss: 0.1505 - val_accuracy: 0.9362\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9790 - val_loss: 0.1493 - val_accuracy: 0.9362\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9790 - val_loss: 0.1481 - val_accuracy: 0.9362\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9790 - val_loss: 0.1470 - val_accuracy: 0.9362\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9790 - val_loss: 0.1461 - val_accuracy: 0.9415\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.1452 - val_accuracy: 0.9415\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.1444 - val_accuracy: 0.9415\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9790 - val_loss: 0.1436 - val_accuracy: 0.9415\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9790 - val_loss: 0.1429 - val_accuracy: 0.9415\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.1422 - val_accuracy: 0.9415\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9790 - val_loss: 0.1416 - val_accuracy: 0.9415\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9790 - val_loss: 0.1409 - val_accuracy: 0.9415\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9843 - val_loss: 0.1403 - val_accuracy: 0.9468\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9843 - val_loss: 0.1396 - val_accuracy: 0.9468\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9843 - val_loss: 0.1391 - val_accuracy: 0.9468\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.1385 - val_accuracy: 0.9468\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.1380 - val_accuracy: 0.9468\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.1374 - val_accuracy: 0.9415\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9843 - val_loss: 0.1368 - val_accuracy: 0.9415\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9843 - val_loss: 0.1363 - val_accuracy: 0.9415\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9843 - val_loss: 0.1358 - val_accuracy: 0.9415\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.1352 - val_accuracy: 0.9415\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9843 - val_loss: 0.1348 - val_accuracy: 0.9415\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9843 - val_loss: 0.1343 - val_accuracy: 0.9415\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.1339 - val_accuracy: 0.9415\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9843 - val_loss: 0.1334 - val_accuracy: 0.9415\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.1330 - val_accuracy: 0.9415\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9843 - val_loss: 0.1326 - val_accuracy: 0.9415\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9843 - val_loss: 0.1323 - val_accuracy: 0.9415\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9843 - val_loss: 0.1320 - val_accuracy: 0.9415\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.1317 - val_accuracy: 0.9415\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.1314 - val_accuracy: 0.9362\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 0.1310 - val_accuracy: 0.9362\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9869 - val_loss: 0.1307 - val_accuracy: 0.9362\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9869 - val_loss: 0.1304 - val_accuracy: 0.9362\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.1301 - val_accuracy: 0.9362\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9869 - val_loss: 0.1298 - val_accuracy: 0.9362\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.1295 - val_accuracy: 0.9362\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.1293 - val_accuracy: 0.9309\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.1290 - val_accuracy: 0.9309\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.1287 - val_accuracy: 0.9309\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.1284 - val_accuracy: 0.9309\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9869 - val_loss: 0.1282 - val_accuracy: 0.9309\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.1279 - val_accuracy: 0.9309\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9869 - val_loss: 0.1277 - val_accuracy: 0.9362\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.1275 - val_accuracy: 0.9362\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9869 - val_loss: 0.1273 - val_accuracy: 0.9362\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 0.1270 - val_accuracy: 0.9362\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9869 - val_loss: 0.1267 - val_accuracy: 0.9362\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.1266 - val_accuracy: 0.9362\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 0.1264 - val_accuracy: 0.9362\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.1260 - val_accuracy: 0.9362\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 0.1259 - val_accuracy: 0.9362\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9869 - val_loss: 0.1256 - val_accuracy: 0.9362\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 0.1254 - val_accuracy: 0.9362\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 0.1253 - val_accuracy: 0.9362\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 0.1251 - val_accuracy: 0.9362\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9869 - val_loss: 0.1251 - val_accuracy: 0.9362\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.1249 - val_accuracy: 0.9362\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9869 - val_loss: 0.1248 - val_accuracy: 0.9362\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.1246 - val_accuracy: 0.9362\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.1245 - val_accuracy: 0.9362\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.1243 - val_accuracy: 0.9362\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.1242 - val_accuracy: 0.9362\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.1241 - val_accuracy: 0.9362\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.1240 - val_accuracy: 0.9362\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.1238 - val_accuracy: 0.9362\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.1237 - val_accuracy: 0.9362\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.1236 - val_accuracy: 0.9362\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.1236 - val_accuracy: 0.9362\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.1235 - val_accuracy: 0.9362\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.1233 - val_accuracy: 0.9362\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.1231 - val_accuracy: 0.9362\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.1228 - val_accuracy: 0.9362\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.1226 - val_accuracy: 0.9362\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.1224 - val_accuracy: 0.9362\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.1221 - val_accuracy: 0.9362\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9895 - val_loss: 0.1221 - val_accuracy: 0.9362\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.1220 - val_accuracy: 0.9362\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9895 - val_loss: 0.1218 - val_accuracy: 0.9362\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.1217 - val_accuracy: 0.9362\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.1214 - val_accuracy: 0.9362\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.1212 - val_accuracy: 0.9362\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9895 - val_loss: 0.1211 - val_accuracy: 0.9362\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.1208 - val_accuracy: 0.9415\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9895 - val_loss: 0.1207 - val_accuracy: 0.9415\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.1206 - val_accuracy: 0.9415\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.1205 - val_accuracy: 0.9415\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.1203 - val_accuracy: 0.9415\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.1204 - val_accuracy: 0.9415\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.1204 - val_accuracy: 0.9415\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.1202 - val_accuracy: 0.9415\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.1202 - val_accuracy: 0.9415\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.1200 - val_accuracy: 0.9415\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.1200 - val_accuracy: 0.9415\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.1200 - val_accuracy: 0.9415\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.1203 - val_accuracy: 0.9415\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.1206 - val_accuracy: 0.9415\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.1205 - val_accuracy: 0.9415\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.1207 - val_accuracy: 0.9415\n"
     ]
    }
   ],
   "source": [
    "#model.fit(X_train, Y_train, batch_size=100, nb_epoch=150)\n",
    "history=model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.97157753e-01],\n",
       "       [9.87037063e-01],\n",
       "       [9.97267604e-01],\n",
       "       [4.30852175e-04],\n",
       "       [9.99972820e-01],\n",
       "       [9.99531269e-01],\n",
       "       [9.99966145e-01],\n",
       "       [5.17113242e-14],\n",
       "       [9.95443642e-01],\n",
       "       [9.99368668e-01],\n",
       "       [1.15191455e-07],\n",
       "       [9.98521686e-01],\n",
       "       [9.79276657e-01],\n",
       "       [9.99484539e-01],\n",
       "       [5.01035458e-07],\n",
       "       [9.99203920e-01],\n",
       "       [9.99268413e-01],\n",
       "       [9.99823451e-01],\n",
       "       [9.02116645e-11],\n",
       "       [1.37044638e-01],\n",
       "       [9.88338649e-01],\n",
       "       [9.99651670e-01],\n",
       "       [9.97923374e-01],\n",
       "       [9.99731779e-01],\n",
       "       [1.81711107e-06],\n",
       "       [9.94153917e-01],\n",
       "       [2.16847525e-07],\n",
       "       [9.99998450e-01],\n",
       "       [8.88111629e-08],\n",
       "       [6.77019358e-04],\n",
       "       [3.50108981e-01],\n",
       "       [1.90292267e-05],\n",
       "       [9.59936142e-01],\n",
       "       [4.28241491e-03],\n",
       "       [9.99964237e-01],\n",
       "       [9.99981880e-01],\n",
       "       [1.33007765e-04],\n",
       "       [4.01171744e-02],\n",
       "       [1.70748660e-08],\n",
       "       [1.80000875e-11],\n",
       "       [9.17973521e-05],\n",
       "       [9.99176145e-01],\n",
       "       [9.98623967e-01],\n",
       "       [9.83836889e-01],\n",
       "       [9.99981642e-01],\n",
       "       [9.98084426e-01],\n",
       "       [5.36347926e-08],\n",
       "       [8.81591439e-01],\n",
       "       [2.02558637e-02],\n",
       "       [9.99799252e-01],\n",
       "       [8.45306715e-07],\n",
       "       [5.90015650e-01],\n",
       "       [9.73375738e-01],\n",
       "       [2.80886290e-15],\n",
       "       [9.98971939e-01],\n",
       "       [9.99228477e-01],\n",
       "       [1.01930295e-08],\n",
       "       [2.57096844e-11],\n",
       "       [9.99203563e-01],\n",
       "       [9.99861240e-01],\n",
       "       [3.40109045e-06],\n",
       "       [2.41730779e-01],\n",
       "       [9.91350412e-01],\n",
       "       [9.99926090e-01],\n",
       "       [1.36349734e-11],\n",
       "       [9.69377995e-01],\n",
       "       [9.61284101e-01],\n",
       "       [4.40872030e-13],\n",
       "       [3.37739664e-07],\n",
       "       [9.93830442e-01],\n",
       "       [3.18091580e-08],\n",
       "       [9.99949574e-01],\n",
       "       [9.99941230e-01],\n",
       "       [9.99821484e-01],\n",
       "       [6.86857007e-08],\n",
       "       [2.34491300e-13],\n",
       "       [9.98405457e-01],\n",
       "       [5.08118808e-01],\n",
       "       [1.11683315e-10],\n",
       "       [3.87457728e-01],\n",
       "       [9.49119210e-01],\n",
       "       [9.10538077e-01],\n",
       "       [9.97015953e-01],\n",
       "       [9.99464154e-01],\n",
       "       [9.95331526e-01],\n",
       "       [9.99991477e-01],\n",
       "       [1.48817897e-03],\n",
       "       [9.94890690e-01],\n",
       "       [3.62048125e-09],\n",
       "       [5.04374504e-02],\n",
       "       [9.81816173e-01],\n",
       "       [1.39077902e-02],\n",
       "       [1.17414747e-04],\n",
       "       [9.68433857e-01],\n",
       "       [9.99896288e-01],\n",
       "       [9.99979317e-01],\n",
       "       [9.98093009e-01],\n",
       "       [2.88542151e-01],\n",
       "       [8.69226369e-06],\n",
       "       [3.14612578e-07],\n",
       "       [7.47301442e-07],\n",
       "       [9.99944985e-01],\n",
       "       [9.98358905e-01],\n",
       "       [9.99985576e-01],\n",
       "       [9.76060033e-01],\n",
       "       [9.98261571e-01],\n",
       "       [9.85944629e-01],\n",
       "       [9.91550207e-01],\n",
       "       [9.95577097e-01],\n",
       "       [9.76814806e-01],\n",
       "       [9.99962568e-01],\n",
       "       [9.99974072e-01],\n",
       "       [9.67020333e-01],\n",
       "       [1.49587631e-05],\n",
       "       [9.75168943e-01],\n",
       "       [9.98390675e-01],\n",
       "       [9.96666670e-01],\n",
       "       [2.57897675e-01],\n",
       "       [1.90711021e-03],\n",
       "       [1.02783927e-10],\n",
       "       [4.89779577e-26],\n",
       "       [4.83805351e-09],\n",
       "       [6.68713662e-09],\n",
       "       [9.98582542e-01],\n",
       "       [2.90686488e-01],\n",
       "       [9.99914408e-01],\n",
       "       [9.98233199e-01],\n",
       "       [9.99927402e-01],\n",
       "       [9.79791880e-01],\n",
       "       [9.96250808e-01],\n",
       "       [8.52087904e-14],\n",
       "       [3.32748031e-11],\n",
       "       [3.84072512e-01],\n",
       "       [9.84917045e-01],\n",
       "       [9.99892712e-01],\n",
       "       [9.87940609e-01],\n",
       "       [4.66941401e-06],\n",
       "       [9.21156097e-05],\n",
       "       [6.76389444e-10],\n",
       "       [9.99999285e-01],\n",
       "       [7.75051490e-07],\n",
       "       [9.61904407e-01],\n",
       "       [3.29706089e-11],\n",
       "       [9.96298969e-01],\n",
       "       [9.93919194e-01],\n",
       "       [8.84029508e-01],\n",
       "       [5.20590365e-01],\n",
       "       [9.99855757e-01],\n",
       "       [3.16204369e-01],\n",
       "       [9.91808116e-01],\n",
       "       [9.99141514e-01],\n",
       "       [3.75330448e-04],\n",
       "       [4.49365079e-02],\n",
       "       [6.13564222e-09],\n",
       "       [9.99974251e-01],\n",
       "       [3.00187386e-09],\n",
       "       [9.99488354e-01],\n",
       "       [8.54005179e-07],\n",
       "       [9.99818563e-01],\n",
       "       [9.95793164e-01],\n",
       "       [8.02778602e-02],\n",
       "       [9.99672890e-01],\n",
       "       [9.99988019e-01],\n",
       "       [4.22472956e-13],\n",
       "       [1.45517643e-05],\n",
       "       [8.70043457e-01],\n",
       "       [9.95418191e-01],\n",
       "       [9.80551839e-01],\n",
       "       [9.99975622e-01],\n",
       "       [5.49572110e-01],\n",
       "       [9.99607205e-01],\n",
       "       [9.99785781e-01],\n",
       "       [7.77134180e-01],\n",
       "       [2.64614820e-04],\n",
       "       [2.83923328e-01],\n",
       "       [9.99899626e-01],\n",
       "       [9.62655783e-01],\n",
       "       [9.98517275e-01],\n",
       "       [9.99408126e-01],\n",
       "       [9.24948335e-01],\n",
       "       [9.99761462e-01],\n",
       "       [5.70951223e-01],\n",
       "       [2.06626787e-08],\n",
       "       [9.99992847e-01],\n",
       "       [9.99818742e-01],\n",
       "       [9.99027252e-01],\n",
       "       [1.76460802e-07],\n",
       "       [9.93369579e-01]], dtype=float32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 94.14893617021278%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1]+ cm[0][1] + cm[1][0]))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASYUlEQVR4nO3dfbRVdZ3H8ff3ckVTfAAVIjBTF1mWk5aWPVvY8wM4LQ3ToqLuVFZqZmFmpmVZpmvKapKpjDWZLDInnCZNI0mdKcLSNATTclLwBgiCD5nch+/8wZnmppd7zz2ce3/3bN4v1l7nnL3P3fsLi/W53/Xbv713ZCaSpJHXVroASdpeGcCSVIgBLEmFGMCSVIgBLEmFtA/3Ae49fLrTLPQE+/12ZekSNAp1b14d27qPrvv/WHfm7LDX/tt8vG1hByxJhQx7ByxJI6q3p3QFdTOAJVVLT3fpCupmAEuqlMze0iXUzQCWVC29BrAklWEHLEmFeBJOkgqxA5akMtJZEJJUiCfhJKkQhyAkqRBPwklSIXbAklSIJ+EkqRBPwklSGZmOAUtSGY4BS1IhDkFIUiEt1AH7SCJJ1dLTVf8yiIj4dkSsjYjf9Vk3ISKujYg7a6/j+2w7PSLuiog7IuI1g+3fAJZULb299S+D+w7w2setmwsszsxpwOLaZyLiIGAW8Kzaz3w9IsYMtHMDWFK1ZG/9y2C7yrwe2PC41TOA+bX384GZfdYvyMzHMvNu4C7g+QPt3wCWVC1D6IAjoiMibuqzdNRxhEmZ2QlQe51YWz8FuLfP91bV1m2VJ+EkVcsQZkFk5jxgXpOOHP0dYqAfMIAlVUrWcXJtG62JiMmZ2RkRk4G1tfWrgH36fG8qcN9AO3IIQlK1NHEMeCuuBGbX3s8GFvVZPysidoyI/YBpwK8G2pEdsKRqaeKFGBFxGXAksFdErALOAs4DFkbEHOAe4BiAzFweEQuB24Fu4MQc5LpoA1hStTTxQozMPG4rm6Zv5fvnAufWu38DWFK1eCmyJBXSQpciG8CSqqXbG7JLUhl2wJJUiGPAklSIHbAkFWIHLEmF2AFLUiHOgpCkQnLAG5CNKgawpGpxDFiSCjGAJakQT8JJUiE9A94BclQxgCVVi0MQklSIASxJhTgGLEllZK/zgCWpDIcgJKkQZ0FIUiF2wJJUiAEsgBi3CxM++VF2OOBpkMmGz3yJzbfdzrhjZzLu2JnQ08OjNy5l00XzSpeqQu76/S956OGH6enppbu7myNe+PrSJbU+b8YjgPGnfpC//mIZ6+eeDe3txE47suPzDuFJL38Rfz7uvdDVRdv4PUqXqcKOetUxrF//QOkyqqNKHXBEPAOYAUwBErgPuDIzVwxzbS0tdtmZHQ89mA1nf2HLiu5u8uFuxr3lTTw4fwF0dQHQ+8DGglVKFdRC09DaBtoYER8HFgAB/ApYVnt/WUTMHf7yWlf7lMn0bNzEhLM+xqTvfoPxZ5xK7LQT7ftOZcdDDmbiJV9l74svZOxBB5YuVQVlJlf9+DKW/vIq3jPn+NLlVENPT/1LYYN1wHOAZ2VmV9+VEXEhsBw4r78fiogOoAPg8/seyPF7T2lCqS1mzBjGHjiNjedfxOblK9nj1BPZ9Z2ziDFjaNt1HGvf9UHGHnQge37uTDpnnlC6WhXysiNn0tm5hr333pOrr1rAHXfcxQ03Li1dVkvLFhqCGLADBnqBp/SzfnJtW78yc15mHpaZh22X4Qv0rF1Hz9p1bF6+EoC/LL6esQdOo3vtOh697kYANt9+B2TStsfuJUtVQZ2dawBYt249ixZdxeGHH1K4ogrozfqXwgYL4JOBxRFxVUTMqy1XA4uBk4a/vNbVu/4Betaso33fqQDsdPihdN39Jx5d8l/sePihALQ/dSrs0E7vxk0lS1UhO+/8JMaN2+Vv71911MtZvvyOwlVVQPbWvxQ24BBEZl4dEU8Hns+Wk3ABrAKWZWb5AZRR7oEvXcSe53wCdtiB7tWdbDjni+Sjf2XCp07jyQu+SXZ1s+HTXyhdpgqZNGlvLv/+twBobx/DggU/5CfXLClbVBWMgs62XpHDPGfu3sOnt86/hkbMfr9dWboEjULdm1fHtu7jkU/NqjtzdjlnwTYfb1s4D1hStYyCoYV6DTYGLEmtpYkn4SLilIhYHhG/i4jLImKniJgQEddGxJ211/GNlmoAS6qU7O2texlIREwBPgwclpnPBsYAs4C5wOLMnMaWCQkNXxNhAEuqluZOQ2sHnhQR7cDObLkSeAYwv7Z9PjCz0VINYEnVMoQAjoiOiLipz9Lxf7vJzNXAl4B7gE5gU2ZeA0zKzM7adzqBiY2W6kk4SdUyhEuMM3Me0O/tCGtjuzOA/YCNwPcjoqmXrRrAkiqlic+EOwq4OzPXAUTEFcCLgDURMTkzOyNiMrC20QM4BCGpWpo3BnwPcERE7BwRAUwHVgBXArNr35kNLGq0VDtgSdXSpJvxZObSiLgc+A3QDdzMluGKccDCiJjDlpA+ptFjGMCSqqWJlyJn5lnAWY9b/RhbuuFtZgBLqpYWuheEASypUrKndS5FNoAlVYsdsCSV0cRpaMPOAJZULQawJBXSOkPABrCkasnu1klgA1hStbRO/hrAkqrFk3CSVIodsCSVYQcsSaXYAUtSGdlduoL6GcCSKqWFnkpvAEuqGANYksqwA5akQgxgSSoke6J0CXUzgCVVih2wJBWSvXbAklSEHbAkFZJpByxJRdgBS1Ihvc6CkKQyPAknSYUYwJJUSLbO7YANYEnVYgcsSYU4DU2SCulxFoQklWEHLEmFtNIYcFvpAiSpmTLrXwYTEXtExOURsTIiVkTECyNiQkRcGxF31l7HN1qrASypUrI36l7q8GXg6sx8BvAcYAUwF1icmdOAxbXPDXEIQlKl9PQ2p6+MiN2AlwHvBMjMzcDmiJgBHFn72nxgCfDxRo5hByypUoYyBBERHRFxU5+lo8+u9gfWAZdExM0R8c2I2AWYlJmdW46VncDERmu1A5ZUKb1DmAWRmfOAeVvZ3A48F/hQZi6NiC+zDcMN/bEDllQpmVH3MohVwKrMXFr7fDlbAnlNREwGqL2ubbRWA1hSpTRrFkRm/hm4NyIOrK2aDtwOXAnMrq2bDSxqtNZhH4I44NY7hvsQakGP3ndD6RJUUUMZgqjDh4BLI2Is8EfgXWxpXBdGxBzgHuCYRnfuGLCkSmnWLAiAzLwFOKyfTdObsX8DWFKltNDdKA1gSdXS5CGIYWUAS6oUb8YjSYW00EORDWBJ1ZLYAUtSEd0OQUhSGXbAklSIY8CSVIgdsCQVYgcsSYX02AFLUhkt9ExOA1hStfTaAUtSGd6MR5IK8SScJBXSGw5BSFIRPaULGAIDWFKlOAtCkgpxFoQkFeIsCEkqxCEISSrEaWiSVEiPHbAklWEHLEmFGMCSVEgLPRLOAJZULXbAklSIlyJLUiHOA5akQhyCkKRCDGBJKqSV7gXRVroASWqm3qh/qUdEjImImyPiR7XPEyLi2oi4s/Y6vtFaDWBJldIzhKVOJwEr+nyeCyzOzGnA4trnhhjAkiqll6x7GUxETAXeAHyzz+oZwPza+/nAzEZrNYAlVUrvEJaI6IiIm/osHY/b3T8DH+Pvz+1NysxOgNrrxEZr9SScpEoZykm4zJwHzOtvW0S8EVibmb+OiCObUdvjGcCSKqWJ09BeDLw5Il4P7ATsFhHfBdZExOTM7IyIycDaRg/gEISkSumOrHsZSGaenplTM/NpwCzgZ5l5AnAlMLv2tdnAokZrtQOWVCkjMA/4PGBhRMwB7gGOaXRHBrCkShmOK+EycwmwpPZ+PTC9Gfs1gCVVSj3Ty0YLA1hSpbRO/BrAkirGm/FIUiE9LdQDG8CSKsUOWJIKSTtgSSqjlTpgr4QbIbvvvhsLLruY225dwq2/vY4XvOC5pUtSgz75uQt52RtmMfOE9/W7/Y9/upfjO07h0CPfxCXfu7wpx9y8eTOnnvl5XnfsuznuvSezunMNACt//weO7ziFGcf/E0e/4/1c9dOfN+V4rayZd0MbbgbwCLnwgrP5yTVLOPgfjuR5h72alSvvKl2SGjTz9a/iGxd+dqvbd99tV+ae8j7eedxbhrzv1Z1reOcHP/aE9Vf86Bp223UcVy38Nm9/60wu/Pq3Adhppx353JkfZdGlF3PxBZ/lC1+5mAcfenjIx62SHMJSmgE8AnbddRwveekLuOSSywDo6upi06YHC1elRh12yMHsvtuuW92+5/g9OPiZB9Le/sQRvv/4yc+Y9Z6TeMvsEzn7i1+hp6e+24L/7IZfMOP1RwHw6iNfytJf30Jm8rSnTmXffaYAMHHvPZkwfg8e2Lipgb9VdXSTdS+lGcAjYP/9nsr96zbwzX+9kF8tvZpv/Mv57Lzzk0qXpRH2h/+5h6sX/5x/+8YF/GD+12hra+NH11xX18+uXbeeJ0/cC4D29jGM22VnNj7ul/htt99BV1c3+0yZ3PTaW0kO4U9pDZ+Ei4h3ZeYlW9nWAXQAjBmzB21jdmn0MJUwpr2dQw99NiefcibLlt3MBReczcdOO5FPn/2l0qVpBC296RZuX3kXs+acBMBjjz3GhPF7APDh089h9X1r6OruonPNOt4y+0QATjh2Bke/4dVkPjEsIv7/oWbr7t/A6eecz7mfPJW2tu27r2qlk3DbMgvibKDfAO57k+OxO04t/2umsNWrO1m1qpNly24G4Ior/pPTTjuxcFUaaZnJm193FKe8/11P2PaVz38K2DIGfMa5F/Cdr37x77ZPmrgXf157P0+euDfd3T08/Mhf/jYM8vAjj/CB0z7Fhzpm85xnP3P4/yKj3GjobOs14K/KiLh1K8ttwKQRqrHlrVmzjlWr7uPpT98fgFe+4iWsWHFn4ao00o447BCuXXIj6x/YCMCmBx/ivj+vqetnX/GSI1j0458CcM2SG3jB855DRNDV1cVJp3+GN792Oq955UuHrfZWMpRHEpU2WAc8CXgN8MDj1gfw38NSUUWdcsqZzP/ORYwdO5a77/4T73nvqaVLUoNOO+s8lt18Kxs3Psj0mSfwgTlvp7u7G4C3Hv0G7l+/gbfO+TAPP/IX2tra+O7CH7Lo0os5YL99+dB730HHyWfQm73s0N7OGR/5AE958uC9zD++8TWc/pnzed2x72b33Xbl/LO3PIj36p/dwK9v+R0bNz3ED2sBfe4ZH+EZTz9g+P4BRrmefoZrRqvob2zpbxsjvgVckpk39rPte5n5tsEO4BCE+vPI6utLl6BRaIe99o/BvzWwt+17dN2Z870//fs2H29bDNgBZ+acAbYNGr6SNNJaaQzYS5ElVcpoGNutlwEsqVJGwyXG9TKAJVWKQxCSVEgrzYIwgCVVikMQklSIJ+EkqRDHgCWpEIcgJKmQga7uHW0MYEmV4mPpJakQhyAkqRCHICSpEDtgSSrEaWiSVEgrXYq8fT+9T1Ll9JJ1LwOJiH0i4rqIWBERyyPipNr6CRFxbUTcWXsd32itBrCkSmlWAAPdwKmZ+UzgCODEiDgImAsszsxpwOLa54YYwJIqJTPrXgbZT2dm/qb2/iFgBTAFmAHMr31tPjCz0VoNYEmVMpQOOCI6IuKmPktHf/uMiKcBhwJLgUmZ2QlbQhqY2GitnoSTVClDmQWRmfOAeQN9JyLGAT8ATs7MByOa9xxPA1hSpfRk825IGRE7sCV8L83MK2qr10TE5MzsjIjJwNpG9+8QhKRKadYYcGxpdb8FrMjMC/tsuhKYXXs/G1jUaK12wJIqpYlXwr0YeDtwW0TcUlv3CeA8YGFEzAHuAY5p9AAGsKRKadaVcJl5I7C1Ad/pzTiGASypUnpb6Eo4A1hSpXgvCEkqpJmzIIabASypUhyCkKRCHIKQpELsgCWpEDtgSSqkJ3tKl1A3A1hSpfhQTkkqxIdySlIhdsCSVIizICSpEGdBSFIhXoosSYU4BixJhTgGLEmF2AFLUiHOA5akQuyAJakQZ0FIUiGehJOkQhyCkKRCvBJOkgqxA5akQlppDDha6bdFq4uIjsycV7oOjS7+v9h+tZUuYDvTUboAjUr+v9hOGcCSVIgBLEmFGMAjy3E+9cf/F9spT8JJUiF2wJJUiAEsSYUYwCMkIl4bEXdExF0RMbd0PSovIr4dEWsj4nela1EZBvAIiIgxwNeA1wEHAcdFxEFlq9Io8B3gtaWLUDkG8Mh4PnBXZv4xMzcDC4AZhWtSYZl5PbChdB0qxwAeGVOAe/t8XlVbJ2k7ZgCPjOhnnfP/pO2cATwyVgH79Pk8FbivUC2SRgkDeGQsA6ZFxH4RMRaYBVxZuCZJhRnAIyAzu4EPAj8BVgALM3N52apUWkRcBvwCODAiVkXEnNI1aWR5KbIkFWIHLEmFGMCSVIgBLEmFGMCSVIgBLEmFGMCSVIgBLEmF/C/qqzMTdpolrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.10117045789957047\n",
      "Test accuracy: 0.9680851101875305\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "x_train:(398, 30)\n",
      "y_train:(398,)\n",
      "\n",
      "x_test:(171, 30)\n",
      "y_test:(171,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=breast_dataset.loc[:, breast_dataset.columns != 'label']\n",
    "y=breast_dataset.label\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "print('Shapes:\\nx_train:%s\\ny_train:%s\\n' % (x_train.shape,y_train.shape))\n",
    "print('x_test:%s\\ny_test:%s\\n'%(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "x_train:(398, 30)\n",
      "y_train:(398,)\n",
      "\n",
      "x_test:(171, 30)\n",
      "y_test:(171,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X=breast_dataset.loc[:, breast_dataset.columns != 'label']\n",
    "y=breast_dataset.label\n",
    "\n",
    "labels = y\n",
    "labels = labels.astype('str')\n",
    "\n",
    "encoded = LabelEncoder()\n",
    "labels = encoded.fit_transform(y)\n",
    "\n",
    "#sc = StandardScaler()\n",
    "#X = sc.fit_transform(X)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.3,\n",
    "                                                   random_state=42)\n",
    "\n",
    "print('Shapes:\\nx_train:%s\\ny_train:%s\\n' % (x_train.shape,y_train.shape))\n",
    "print('x_test:%s\\ny_test:%s\\n'%(x_test.shape,y_test.shape))\n",
    "#x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', random_state=42)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100,\n",
    "                                   bootstrap=True,\n",
    "                                   max_features='sqrt',\n",
    "                                   random_state=42\n",
    "                                      )\n",
    "\n",
    "rf_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03, 0.97],\n",
       "       [1.  , 0.  ],\n",
       "       [0.97, 0.03],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.76, 0.24],\n",
       "       [0.02, 0.98],\n",
       "       [0.01, 0.99],\n",
       "       [0.95, 0.05],\n",
       "       [0.11, 0.89],\n",
       "       [0.89, 0.11],\n",
       "       [0.  , 1.  ],\n",
       "       [0.98, 0.02],\n",
       "       [0.06, 0.94],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.24, 0.76],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.01, 0.99],\n",
       "       [0.08, 0.92],\n",
       "       [0.01, 0.99],\n",
       "       [0.08, 0.92],\n",
       "       [0.  , 1.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.02, 0.98],\n",
       "       [0.  , 1.  ],\n",
       "       [0.25, 0.75],\n",
       "       [0.11, 0.89],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.62, 0.38],\n",
       "       [0.06, 0.94],\n",
       "       [1.  , 0.  ],\n",
       "       [0.07, 0.93],\n",
       "       [0.  , 1.  ],\n",
       "       [0.94, 0.06],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.34, 0.66],\n",
       "       [0.04, 0.96],\n",
       "       [0.05, 0.95],\n",
       "       [0.02, 0.98],\n",
       "       [0.02, 0.98],\n",
       "       [0.05, 0.95],\n",
       "       [0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.21, 0.79],\n",
       "       [0.01, 0.99],\n",
       "       [0.01, 0.99],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.79, 0.21],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.04, 0.96],\n",
       "       [0.  , 1.  ],\n",
       "       [0.17, 0.83],\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.  , 1.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.89, 0.11],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.98, 0.02],\n",
       "       [0.01, 0.99],\n",
       "       [0.08, 0.92],\n",
       "       [0.05, 0.95],\n",
       "       [0.42, 0.58],\n",
       "       [0.  , 1.  ],\n",
       "       [0.16, 0.84],\n",
       "       [0.97, 0.03],\n",
       "       [0.  , 1.  ],\n",
       "       [0.31, 0.69],\n",
       "       [1.  , 0.  ],\n",
       "       [0.77, 0.23],\n",
       "       [0.97, 0.03],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.98, 0.02],\n",
       "       [0.01, 0.99],\n",
       "       [0.02, 0.98],\n",
       "       [0.  , 1.  ],\n",
       "       [0.21, 0.79],\n",
       "       [0.23, 0.77],\n",
       "       [0.03, 0.97],\n",
       "       [0.01, 0.99],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.91, 0.09],\n",
       "       [0.  , 1.  ],\n",
       "       [0.96, 0.04],\n",
       "       [1.  , 0.  ],\n",
       "       [0.02, 0.98],\n",
       "       [0.01, 0.99],\n",
       "       [0.02, 0.98],\n",
       "       [1.  , 0.  ],\n",
       "       [0.45, 0.55],\n",
       "       [0.16, 0.84],\n",
       "       [0.97, 0.03],\n",
       "       [0.  , 1.  ],\n",
       "       [0.31, 0.69],\n",
       "       [1.  , 0.  ],\n",
       "       [0.27, 0.73],\n",
       "       [0.99, 0.01],\n",
       "       [0.  , 1.  ],\n",
       "       [0.06, 0.94],\n",
       "       [0.  , 1.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.38, 0.62],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.03, 0.97],\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.  , 1.  ],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [0.92, 0.08],\n",
       "       [0.99, 0.01],\n",
       "       [0.13, 0.87],\n",
       "       [0.  , 1.  ],\n",
       "       [0.15, 0.85],\n",
       "       [0.93, 0.07],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.35, 0.65],\n",
       "       [0.97, 0.03],\n",
       "       [0.  , 1.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.95, 0.05],\n",
       "       [0.01, 0.99],\n",
       "       [1.  , 0.  ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.53, 0.47],\n",
       "       [0.  , 1.  ],\n",
       "       [0.77, 0.23],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.  , 1.  ],\n",
       "       [0.06, 0.94],\n",
       "       [0.98, 0.02],\n",
       "       [1.  , 0.  ],\n",
       "       [0.03, 0.97],\n",
       "       [0.05, 0.95],\n",
       "       [0.  , 1.  ],\n",
       "       [0.05, 0.95],\n",
       "       [0.03, 0.97],\n",
       "       [0.02, 0.98],\n",
       "       [0.03, 0.97],\n",
       "       [0.42, 0.58],\n",
       "       [0.  , 1.  ],\n",
       "       [0.01, 0.99],\n",
       "       [0.12, 0.88],\n",
       "       [0.01, 0.99],\n",
       "       [0.84, 0.16],\n",
       "       [0.27, 0.73]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual class predictions\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "# Probabilities for each class\n",
    "rf_probs = rf_classifier.predict_proba(x_test)[:,] # 5 clusters from hdbscan\n",
    "rf_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class   0    1\n",
      "Actual Class            \n",
      "0                59    4\n",
      "1                 1  107\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Class'], colnames=['Predicted Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        60\n",
      "           1       0.99      0.96      0.98       111\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.96      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 97.07602339181285%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1]+ cm[0][1] + cm[1][0]))*100))\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
